{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Reddit Data Collection</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>The following script was used to access the Reddit data using the PRAW package. PRAW stands for Python Reddit API Wrapper. It follows all of the Reddit's API rules.<b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>1.1</b> To use this API, the developer is required to create an app with Reddit which generates a Client ID and Client Secret. I created a Reddit account to create the app and stored my credentials in a JSON file. This is important as these values should be protected and not be hard coded in the main python script (as this could make them vulnerable to misuse when uploaded publicaly on GitHub). <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading secret keys from reddit_api.json where I have stored all the values in a dictionary \n",
    "import json\n",
    "url = \"https://www.reddit.com/\"\n",
    "redirect_uri = \"https://www.reddit.com/\"\n",
    "with open(\"/Users/alkaa/.secret/reddit_api.json\") as f:\n",
    "    param = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>1.2</b> Importing the PRAW wrapper and authorizing the Reddit instance: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Reddit instance using praw\n",
    "import praw\n",
    "reddit = praw.Reddit(client_id = param['client_id'],\n",
    "                     client_secret = param['api_key'],\n",
    "                     username = param['username'],\n",
    "                     password = param['password'],\n",
    "                     user_agent = param['useragent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>1.3</b> In the following cell, I am collecting the required data for running the Exploratory Data Analysis on a small set of values from the 'India' Subreddit.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit('India')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>1.4</b> Declaring the flair list so we are taking 10 flairs into consideration. </p> \n",
    "\n",
    "<i> The following two cells answer \"What all\" to collect the data as expected in Task I. We will be collecting the data on the basis of flair so we have enough data for each flair. </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs = ['Non-Political',\n",
    "          'Scheduled', \n",
    "          'Photography',  \n",
    "          'Politics', \n",
    "          'Business/Finance', \n",
    "          'Policy/Economy', \n",
    "          'Sports', \n",
    "          'Food', \n",
    "          'AskIndia',\n",
    "          'Coronavirus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>1.5</b> This dictionary comprises of the parameters we will be considering for each post </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "india_dict = {\n",
    "    \"flair\":[],\n",
    "    \"title\":[],\n",
    "    \"url\":[],\n",
    "    \"body\":[],\n",
    "    \"num_comments\":[],\n",
    "    \"comments\":[],\n",
    "    \"score\":[],\n",
    "    \"id\":[]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>1.6</b> Based on my research of similar projects and my machine's capacity, I have decided to collect 200 posts for each flair under consideration.</p>\n",
    "\n",
    "<i> The following cell answers \"How Much\" as expected in Task I. </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flair in flairs:\n",
    "    flair_data = subreddit.search(flair, limit=200)\n",
    "    i=0\n",
    "    for submission in flair_data:\n",
    "        i+=1\n",
    "        india_dict['flair'].append(flair)\n",
    "        india_dict['title'].append(submission.title)\n",
    "        india_dict['url'].append(submission.url)\n",
    "        india_dict['body'].append(submission.selftext)\n",
    "        india_dict['num_comments'].append(submission.num_comments)\n",
    "        \n",
    "        india_dict['score'].append(submission.score)\n",
    "        india_dict['id'].append(submission.id)\n",
    "        \n",
    "        submission.comments.replace_more(limit=None)\n",
    "        comment = ''\n",
    "        for top_level_comment in submission.comments:\n",
    "            comment = comment + ' ' + top_level_comment.body\n",
    "        india_dict[\"comments\"].append(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>1.7 </b> Loading the python dictionary data into CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "india_data = pd.DataFrame(india_dict)\n",
    "india_data.to_csv('reddit-india-data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
